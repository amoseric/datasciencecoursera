
```{r }
# Project for Practical Machine Learning, 2015 April, Amos
#
# Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to 
# collect a large amount of data about personal activity relatively inexpensively. 
# These type of devices are part of the quantified self movement â€“ a group of 
# enthusiasts who take measurements about themselves regularly to improve their 
# health, to find patterns in their behavior, or because they are tech geeks. One 
# thing that people regularly do is quantify how much of a particular activity they 
# do, but they rarely quantify how well they do it. In this project, the goal will 
# be to use data from accelerometers on the belt, forearm, arm, and dumbell of 
# 6 participants. They were asked to perform barbell lifts correctly and incorrectly 
# in 5 different ways.
#
# This report shows how a model is bulit, its cross validation, the expected 
# out-of-sample error and model choices. In the end the prediction model is used 
# to predict 20 different test cases. 

# The data for this project come from this source: 
# http://groupware.les.inf.puc-rio.br/har. 
  
train = read.csv("pml-training.csv")
test = read.csv("pml-testing.csv")
dim(train)
table(train$classe)


library(caret)

set.seed(999)
partList = createDataPartition(train$classe, p = 0.7, list = FALSE)
trainingSet = train[partList,]
validationSet = train[-partList,]


# Cleaning up the data:
# Remove the first 7 variables as they are not motion related variables
#
trainingSet = trainingSet[,-(1:7)]
dim(trainingSet)


# Remove variables with near zero variance
#
nzvCol = nearZeroVar(trainingSet)
trainingSet = trainingSet[, -nzvCol]


# Remove variables that have 60% or higher NA values
#
unwantedCol = vector()
index = 0
for (i in 1:ncol(trainingSet)) {
    if ((sum(is.na(trainingSet[,i]))/nrow(trainingSet)) >= 0.6) {
        index = index + 1
        unwantedCol[index] = i
    }
}
trainingSet = trainingSet[,-unwantedCol]
dim(trainingSet)


# Likewise, remove the unwanted variables from validation and test sets
#
validationSet = validationSet[colnames(trainingSet)]
dim(validationSet)
test = test[colnames(trainingSet[,-53])]
dim(test)


# [1] Build CART Model on training set
#
library(rpart)
cartModel = rpart(classe ~ ., data = trainingSet, method = "class", 
                  cp = 0.001)

# Training set accuracy using CART Model
#
trainingPredict1 = predict(cartModel, type = "class")
print(confusionMatrix(trainingPredict1, trainingSet$classe))


# [2] Build Random-Forest Model on training set
#
library(randomForest)
rfModel <- randomForest(classe ~ ., data = trainingSet, 
                        importance = TRUE, ntrees = 10)

# Training set accuracy using RF Model
#
trainingPredict <- predict(rfModel, trainingSet)
print(confusionMatrix(trainingPredict, trainingSet$classe))

# Accuracy of validation set (Out of Sample)
#
validationPredict <- predict(rfModel, validationSet)
print(confusionMatrix(validationPredict, validationSet$classe))


# Result:
# Random-Forest Model is preferred over CART Model as it has higher training
# set accuracy.
# Using Random-Forest Model, the cross validation accuracy is 99.54% and 
# therefore the expected out-of-sample error is 0.46% (100% - 99.54%).
# This model is selected to predict classe variable in the given test set.


# Prediction on test set
#
testPredict <- predict(rfModel, test)
testPredict

# Save answers onto files for later submission
#
pml_write_files = function(x) {
  n = length(x)
  for (i in 1:n) {
    filename = paste0("problem_id_", i, ".txt")
    write.table(x[i], file = filename, quote = FALSE, 
                row.names = FALSE,
                col.names = FALSE)
  }
}
pml_write_files(as.vector(testPredict))
```


---
title: "PML_Project_Writeup.R"
author: "song"
date: "Sat Apr 25 16:49:18 2015"
---
